---
---

@misc{https://doi.org/10.48550/arxiv.2104.07153,
  doi = {10.48550/ARXIV.2104.07153},
  html = {https://arxiv.org/abs/2104.07153},
  author = {Cuadra, Andrea and Lee, Hansol and Cho, Jason and Ju, Wendy},
  keywords = {Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Look at Me When I Talk to You: A Video Dataset to Enable Voice Assistants to Recognize Errors},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license},
  abbr = {arXiv},
  abstract = {People interacting with voice assistants are often frustrated by voice assistants' frequent errors and inability to respond to backchannel cues. We introduce an open-source video dataset of 21 participants' interactions with a voice assistant, and explore the possibility of using this dataset to enable automatic error recognition to inform self-repair. The dataset includes clipped and labeled videos of participants' faces during free-form interactions with the voice assistant from the smart speaker's perspective. To validate our dataset, we emulated a machine learning classifier by asking crowdsourced workers to recognize voice assistant errors from watching soundless video clips of participants' reactions. We found trends suggesting it is possible to determine the voice assistant's performance from a participant's facial reaction alone. This work posits elicited datasets of interactive responses as a key step towards improving error recognition for repair for voice assistants in a wide variety of applications.}
}

@article{LAMWITTY,
  doi = {10.1145/3449101},
  html = {https://doi.org/10.1145/3449101},
  year = 2021,
  month = {apr},
  publisher = {Association for Computing Machinery ({ACM})},
  volume = {5},
  number = {{CSCW}1},
  pages = {1--24},
  author = {Andrea Cuadra and Shuran Li and Hansol Lee and Jason Cho and Wendy Ju},
  title = {My Bad! Repairing Intelligent Voice Assistant Errors Improves Interaction},
  journal = {Proceedings of the {ACM} on Human-Computer Interaction},
  abbr = {CSCW},
  abstract = {One key technique people use in conversation and collaboration is conversational repair. Self-repair is the recognition and attempted correction of one's own mistakes. We investigate how the self-repair of errors by intelligent voice assistants affects user interaction. In a controlled human-participant study (N =101), participants asked Amazon Alexa to perform four tasks, and we manipulated whether Alexa would "make a mistake'' understanding the participant (for example, playing heavy metal in response to a request for relaxing music) and whether Alexa would perform a correction (for example, stating, "You don't seem pleased. Did I get that wrong?'') We measured the impact of self-repair on the participant's perception of the interaction in four conditions: correction (mistakes made and repair performed), undercorrection (mistakes made, no repair performed), overcorrection (no mistakes made, but repair performed), and control (no mistakes made, and no repair performed). Subsequently, we conducted free-response interviews with each participant about their interactions. This study finds that self-repair greatly improves people's assessment of an intelligent voice assistant if a mistake has been made, but can degrade assessment if no correction is needed. However, we find that the positive impact of self-repair in the wake of an error outweighs the negative impact of overcorrection. In addition, participants who recently experienced an error saw increased value in self-repair as a feature, regardless of whether they experienced a repair themselves.}
}
